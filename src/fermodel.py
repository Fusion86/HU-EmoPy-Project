"""
Contains the logic for our CNN.
"""

import os
import cv2
import time
import numpy as np
import onnxruntime
import matplotlib.pyplot as plt


class FERModel:
    def __init__(self, model_path):
        self.dimensions = (64, 64)
        self.model_path = model_path
        self.session = onnxruntime.InferenceSession(self.model_path, None)

        self.input_data_name = self.session.get_inputs()[0].name
        self.input_emotion_name = self.session.get_inputs()[1].name
        self.output_name = self.session.get_outputs()[2].name
        self.emotion_table = [[0, 1, 2, 3, 4, 5, 6, 7]]

        for x in self.session.get_inputs():
            print("Input: {}".format(x))

        for x in self.session.get_outputs():
            print("Output: {}".format(x))

    # TODO: Document this
    def predict(self, image):
        """Predict the emotion in an image.

        Args:
            image: image data as read by cv2.imread(file)
                If no_prepro
        """
        # Check if image is already grayscale
        if image.shape[2] == 1:
            gray_start = 0
            gray_end = 0
            gray_image = image
        else:
            gray_start = time.time_ns()
            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            gray_end = time.time_ns()

        # Check if image is already resized
        if image.shape[0] == self.dimensions[0] and image.shape[1] == self.dimensions[1]:
            resize_start = 0
            resize_end = 0
            resized = gray_image
        else:
            resize_start = time.time_ns()
            resized = cv2.resize(gray_image, self.dimensions,
                                 interpolation=cv2.INTER_AREA)
            resize_end = time.time_ns()

        # Transform data
        data = np.array(resized, dtype=np.float32)
        input_data = np.array([data]).reshape(
            [1] + [1] + list(self.dimensions))

        model_start = time.time_ns()
        res = self.session.run([self.output_name], {
            self.input_data_name: input_data, self.input_emotion_name: self.emotion_table})
        model_end = time.time_ns()

        processed, probability = self.postprocess(res[0])
        emotions = FERModel.emotion_map(processed, len(processed))

        return {
            "emotions": emotions,
            "probabilities": probability,
            "runtime": {
                "grayscale": gray_end - gray_start,
                "resize": resize_end - resize_start,
                "model": model_end - model_start
            }}

    @staticmethod
    def softmax(x):
        """Compute softmax values (probabilities from 0 to 1) for each possible label."""
        x = x.reshape(-1)
        e_x = np.exp(x - np.max(x))
        return e_x / e_x.sum(axis=0)

    @staticmethod
    def postprocess(scores):
        """This function takes the scores generated by the network and
        returns the class IDs in decreasing order of probability."""
        prob = FERModel.softmax(scores)
        prob = np.squeeze(prob)

        classes = np.argsort(prob)
        classes = classes[::-1]

        probability = []
        for i in classes:
            probability.append(
                round(float(np.format_float_positional(prob[i] * 100)), 2))

        return classes, probability

    @staticmethod
    def emotion_map(classes, N=1):
        """Take the most probable labels (output of postprocess) and returns the
        top N emotional labels that fit the picture."""

        emotion_table = {"neutral": 0, "happiness": 1, "surprise": 2, "sadness": 3,
                         "anger": 4, "disgust": 5, "fear": 6, "contempt": 7}

        emotion_keys = list(emotion_table.keys())
        emotions = []
        for i in range(N):
            emotions.append(emotion_keys[classes[i]])
        return emotions


if __name__ == "__main__":
    def print_runtime(name, time):
        print("Runtime {:10} avg: {: 10.6f}ms  stdev: {: 10.6f}ms".format(
            name, mean(time) / 1000_000, stdev(time) / 1000_000))

    from statistics import stdev, mean

    model = FERModel("model.onnx")
    iterations = 10

    for root, dirs, files in os.walk(os.path.abspath("../images")):
        for file in files:
            absfile = os.path.join(root, file)

            emotions = None
            probabilies = None

            # Time is in nanoseconds
            time_grayscale = list()
            time_resize = list()
            time_model = list()

            for _ in range(iterations):
                image = cv2.imread(absfile)
                res = model.predict(image)

                # Shouldn't change between runs
                emotions = res['emotions']
                probabilies = res['probabilities']

                time_grayscale.append(res['runtime']['grayscale'])
                time_resize.append(res['runtime']['resize'])
                time_model.append(res['runtime']['model'])

            print("\n")
            print("File: {}".format(file))
            print("Emotions: {}".format(emotions))
            print("Probabilities: {}".format(probabilies))

            print_runtime("grayscale", time_grayscale)
            print_runtime("resize", time_grayscale)
            print_runtime("model", time_model)
